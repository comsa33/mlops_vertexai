{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"copyright"},"outputs":[],"source":["# Copyright 2024 Forusone(shins777@gmail.com)\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"title:generic"},"source":["# Custom training with pipeline - Tabular data regression\n","\n","This notebook is simplified version of the below notebook in the official Google github. You can find more divese codes and detailed information from the link.\n","\n","* [Vertex AI Pipelines](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/google_cloud_pipeline_components_model_train_upload_deploy.ipynb)\n","\n","* [github - pipelines examples](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/)\n","\n","### Dataset\n","\n","The dataset used for this tutorial is [Cloud Public Dataset Program](https://cloud.google.com/bigquery/public-data/) [London Bikes Rental](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=london_bicycles&page=dataset&_ga=2.122237643.-1779725180.1624895157) combined with [NOAA weather data ](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=noaa_gsod&page=dataset&_ga=2.179861860.-1779725180.1624895157) The dataset predicts the duration of the bike rental.\n"]},{"cell_type":"markdown","metadata":{"id":"a2c2cb2109a0"},"source":["### Install Vertex AI SDK\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"install_aip:mbsdk","executionInfo":{"status":"ok","timestamp":1735822566570,"user_tz":-540,"elapsed":8527,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"61f8ee2d-6733-4bd5-e85d-f1b351f8f41f"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["%pip install --upgrade --quiet --user google-cloud-aiplatform \\\n","                                      google-cloud-pipeline-components \\\n","                                      google-cloud-storage \\\n","                                      kfp"]},{"cell_type":"code","source":["# @title Check package version\n","! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n","! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"08pp7Q6jIqAd","executionInfo":{"status":"ok","timestamp":1735822580966,"user_tz":-540,"elapsed":1936,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"c78eb90f-d05e-4545-ec72-f99e112f4c6b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["KFP SDK version: 2.10.1\n","google_cloud_pipeline_components version: 2.18.0\n"]}]},{"cell_type":"code","source":["# @title Authentication to access to GCP\n","# To use markdown for output data from LLM\n","from IPython.display import display, Markdown\n","\n","# Use OAuth to access the GCP environment.\n","import sys\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"id":"MVnZtKr4GK6A","executionInfo":{"status":"ok","timestamp":1735822818831,"user_tz":-540,"elapsed":167,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# @title Define constants\n","PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n","LOCATION = \"us-central1\"  # @param {type:\"string\"}"],"metadata":{"id":"c29fptUbGPbk","executionInfo":{"status":"ok","timestamp":1735822821032,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46604f70e831","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733642404391,"user_tz":-540,"elapsed":16216,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"4c6f48d5-1592-4ee5-c5a5-8d65fc436216"},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated property [core/project].\n"]}],"source":["# import sys\n","# from IPython.display import Markdown, display\n","\n","# PROJECT_ID=\"ai-hangsik\"\n","# LOCATION=\"us-central1\"\n","\n","# # For only colab user, no need this process for Colab Enterprise in Vertex AI.\n","# if \"google.colab\" in sys.modules:\n","#     from google.colab import auth\n","#     auth.authenticate_user(project_id=PROJECT_ID)\n","\n","# # set project.\n","# !gcloud config set project {PROJECT_ID}"]},{"cell_type":"code","source":["# @title Import libraries\n","from typing import NamedTuple\n","from typing import Any, Dict, List\n","\n","import google.cloud.aiplatform as aiplatform\n","\n","import kfp\n","from google.cloud import bigquery\n","from kfp import compiler, dsl\n","from kfp.dsl import ( Artifact,\n","                      ClassificationMetrics,\n","                      Input,\n","                      Metrics,\n","                      Output,\n","                      component)\n"],"metadata":{"id":"l3nOZMubJM0N","executionInfo":{"status":"ok","timestamp":1735823020328,"user_tz":-540,"elapsed":40,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Data preparation"],"metadata":{"id":"T-YMpoMGJXPt"}},{"cell_type":"code","source":["# @title Create a bucket.\n","BUCKET_URI = f\"gs://mlops-{PROJECT_ID}-0103\"\n","! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9PJDg-gJU_f","executionInfo":{"status":"ok","timestamp":1735822939874,"user_tz":-540,"elapsed":2922,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"41cbf1ca-cefe-4dfe-9db2-1917880485ab"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating gs://mlops-ai-hangsik-0103/...\n"]}]},{"cell_type":"code","source":["# @title Vertex AI Pipelines constants\n","\n","import datetime\n","\n","now = datetime.datetime.now()\n","now_format = now.strftime('%Y%m%d-%H%M%S')\n","\n","PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline/costom/custom_tabular_regression_pipeline\"\n","WORKING_DIR = f\"{PIPELINE_ROOT}/{now_format}\"\n","MODEL_DISPLAY_NAME = f\"custom_tabular_regression_pipeline_{now_format}\"\n","\n","hp_dict: str = '{\"num_hidden_layers\": 3, \"hidden_size\": 32, \"learning_rate\": 0.01, \"epochs\": 1, \"steps_per_epoch\": -1}'\n","data_dir: str = (\n","    \"gs://cloud-samples-data/vertex-ai/pipeline-deployment/datasets/bikes_weather/\"\n",")\n","\n","TRAINER_ARGS = [\"--data-dir\", data_dir, \"--hptune-dict\", hp_dict]\n","\n","print(TRAINER_ARGS, WORKING_DIR, MODEL_DISPLAY_NAME)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDJEz3X5KBYP","executionInfo":{"status":"ok","timestamp":1735822954938,"user_tz":-540,"elapsed":16,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"eca5e48a-333a-4b2a-86d2-48ca5a83e3a5"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["['--data-dir', 'gs://cloud-samples-data/vertex-ai/pipeline-deployment/datasets/bikes_weather/', '--hptune-dict', '{\"num_hidden_layers\": 3, \"hidden_size\": 32, \"learning_rate\": 0.01, \"epochs\": 1, \"steps_per_epoch\": -1}'] gs://mlops-ai-hangsik-0103/pipeline/costom/custom_tabular_regression_pipeline/20250102-130234 custom_tabular_regression_pipeline_20250102-130234\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Mg7-LrhXl7Hm","executionInfo":{"status":"ok","timestamp":1735823023815,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["# @title Initialize Vertex AI SDK for Python\n","aiplatform.init(project=PROJECT_ID, staging_bucket=BUCKET_URI)"]},{"cell_type":"markdown","metadata":{"id":"define_pipeline:gcpc,bikes_weather,lrg"},"source":["## Define custom model pipeline that uses components from `google_cloud_pipeline_components`\n","\n","Next, you define the pipeline.\n","\n","The `experimental.run_as_aiplatform_custom_job` method takes as arguments the previously defined component, and the list of `worker_pool_specs`— in this case one— with which the custom training job is configured.\n","\n","Then, [`google_cloud_pipeline_components`](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud) components are used to define the rest of the pipeline: upload the model, create an endpoint, and deploy the model to the endpoint.\n","\n","*Note:* While not shown in this example, the model deploy will create an endpoint if one is not provided."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"e15BUYPOl7Hm","executionInfo":{"status":"ok","timestamp":1735823070559,"user_tz":-540,"elapsed":46,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["\n","@kfp.dsl.pipeline(name=\"custom_tabular_regression_pipeline\" + now_format)\n","def pipeline(\n","    project: str = PROJECT_ID,\n","    model_display_name: str = MODEL_DISPLAY_NAME,\n","    serving_container_image_uri: str = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-9:latest\",\n","):\n","    from google_cloud_pipeline_components.types import artifact_types\n","    from google_cloud_pipeline_components.v1.custom_job import \\\n","        CustomTrainingJobOp\n","    from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,\n","                                                              ModelDeployOp)\n","    from google_cloud_pipeline_components.v1.model import ModelUploadOp\n","    from kfp.dsl import importer_node\n","\n","    custom_job_task = CustomTrainingJobOp(\n","        project=project,\n","        display_name=\"custom_tabular_regression_pipeline\",\n","        worker_pool_specs=[\n","            {\n","                \"containerSpec\": {\n","                    \"args\": TRAINER_ARGS,\n","                    \"env\": [{\"name\": \"AIP_MODEL_DIR\", \"value\": WORKING_DIR}],\n","                    \"imageUri\": \"gcr.io/google-samples/bw-cc-train:latest\",\n","                },\n","                \"replicaCount\": \"1\",\n","                \"machineSpec\": {\n","                    \"machineType\": \"n1-standard-4\",\n","                },\n","            }\n","        ],\n","    )\n","\n","    import_unmanaged_model_task = importer_node.importer(\n","        artifact_uri=WORKING_DIR,\n","        artifact_class=artifact_types.UnmanagedContainerModel,\n","        metadata={\n","            \"containerSpec\": {\n","                \"imageUri\": \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-9:latest\",\n","            },\n","        },\n","    ).after(custom_job_task)\n","\n","    model_upload_op = ModelUploadOp(\n","        project=project,\n","        display_name=model_display_name,\n","        unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n","    )\n","    model_upload_op.after(import_unmanaged_model_task)\n","\n","    endpoint_create_op = EndpointCreateOp(\n","        project=project,\n","        display_name=\"custom_tabular_regression_pipeline\",\n","    )\n","\n","    ModelDeployOp(\n","        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n","        model=model_upload_op.outputs[\"model\"],\n","        deployed_model_display_name=model_display_name,\n","        dedicated_resources_machine_type=\"n1-standard-4\",\n","        dedicated_resources_min_replica_count=1,\n","        dedicated_resources_max_replica_count=1,\n","    )"]},{"cell_type":"markdown","metadata":{"id":"compile_pipeline"},"source":["## Compile the pipeline\n","\n","Next, compile the pipeline."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"fi5ukWhwl7Hn","executionInfo":{"status":"ok","timestamp":1735823073418,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["compiler.Compiler().compile(\n","    pipeline_func=pipeline,\n","    package_path=\"custom_tabular_regression_pipeline.json\",\n",")"]},{"cell_type":"markdown","metadata":{"id":"run_pipeline:custom"},"source":["## Run the pipeline\n","\n","Next, run the pipeline."]},{"cell_type":"code","source":["shell_output = ! gcloud projects describe  $PROJECT_ID\n","project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n","\n","SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n","\n","print(f\"SERVICE_ACCOUNT: {SERVICE_ACCOUNT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mj1YvUMPLLQW","executionInfo":{"status":"ok","timestamp":1735823077298,"user_tz":-540,"elapsed":1649,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"f9b7e534-73e4-46ca-b4e5-2a65be267667"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["SERVICE_ACCOUNT: 721521243942-compute@developer.gserviceaccount.com\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ywe4Ney1l7Hn","outputId":"7fa2fbe8-ecfd-48f8-8a48-399c75ee3e73","executionInfo":{"status":"ok","timestamp":1735827584956,"user_tz":-540,"elapsed":4505325,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439\n","INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n","INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439')\n","INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n","https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/custom-tabular-regression-pipeline20250102-130234-20250102130439?project=721521243942\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/721521243942/locations/us-central1/pipelineJobs/custom-tabular-regression-pipeline20250102-130234-20250102130439\n"]}],"source":["DISPLAY_NAME = \"custom_tabular_regression_pipeline_\" + now_format\n","\n","job = aiplatform.PipelineJob(\n","    display_name=DISPLAY_NAME,\n","    template_path=\"custom_tabular_regression_pipeline.json\",\n","    pipeline_root=PIPELINE_ROOT,\n","    enable_caching=False,\n",")\n","\n","\n","job.run(service_account=SERVICE_ACCOUNT)\n","\n","# ! rm tabular_regression_pipeline.json"]},{"cell_type":"markdown","metadata":{"id":"view_pipeline_run:custom"},"source":["Click on the generated link to see your run in the Cloud Console.\n","\n","<!-- It should look something like this as it is running:\n","\n","<a href=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" width=\"40%\"/></a> -->\n","\n","In the UI, many of the pipeline DAG nodes will expand or collapse when you click on them. Here is a partially-expanded view of the DAG (click image to see larger version).\n","\n","<a href=\"https://storage.googleapis.com/amy-jo/images/mp/train_endpoint_deploy.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/train_endpoint_deploy.png\" width=\"75%\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"cleanup:pipelines"},"source":["# Cleaning up\n","\n","To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n","project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n","\n","Otherwise, you can delete the individual resources you created in this tutorial -- *Note:* this is auto-generated and not all resources may be applicable for this tutorial:\n","### Get resources from the pipline to clean up\n","Function to get details of a task"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"50f5f0d96294"},"outputs":[],"source":["def get_task_detail(\n","    task_details: List[Dict[str, Any]], task_name: str\n",") -> List[Dict[str, Any]]:\n","    for task_detail in task_details:\n","        if task_detail.task_name == task_name:\n","            return task_detail"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0966cd56fc3e"},"outputs":[],"source":["pipeline_task_details = (\n","    job.gca_resource.job_detail.task_details\n",")  # fetch pipeline task details\n","\n","\n","# fetch endpoint from pipeline and delete the endpoint\n","endpoint_task = get_task_detail(pipeline_task_details, \"endpoint-create\")\n","endpoint_resourceName = (\n","    endpoint_task.outputs[\"endpoint\"].artifacts[0].metadata[\"resourceName\"]\n",")\n","endpoint = aip.Endpoint(endpoint_resourceName)\n","# undeploy model from endpoint\n","endpoint.undeploy_all()\n","endpoint.delete()\n","\n","# fetch model from pipeline and delete the model\n","model_task = get_task_detail(pipeline_task_details, \"model-upload\")\n","model_resourceName = model_task.outputs[\"model\"].artifacts[0].metadata[\"resourceName\"]\n","model = aip.Model(model_resourceName)\n","model.delete()\n","\n","job.delete()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oA9R36UGl7Hp"},"outputs":[],"source":["delete_bucket = False\n","if delete_bucket:\n","    ! gsutil rm -r $BUCKET_URI"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"copyright"},"outputs":[],"source":["# Copyright 2024 Forusone(shins777@gmail.com)\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"title:generic,gcp"},"source":["# Experiments - Training\n","\n","* [Get started with Vertex AI Experiments](https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/get_started_with_vertex_experiments.ipynb?hl=ko#scrollTo=title%3Ageneric%2Cgcp)"]},{"cell_type":"markdown","metadata":{"id":"No17Cw5hgx12"},"source":["### Install Vertex AI SDK for Python and other required packages\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"install_mlops","executionInfo":{"status":"ok","timestamp":1735868227156,"user_tz":-540,"elapsed":8490,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["! pip3 install --upgrade --quiet --user google-cloud-aiplatform"]},{"cell_type":"code","source":["# @title Authentication to GCP\n","import sys\n","\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user()"],"metadata":{"id":"osJi7DvnobNH","executionInfo":{"status":"ok","timestamp":1735868237852,"user_tz":-540,"elapsed":10674,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# @title Set GCP information\n","PROJECT_ID = \"ai-hangsik\"  # @param {type:\"string\"}\n","LOCATION = \"us-central1\"  # @param {type:\"string\"}"],"metadata":{"id":"tzWmcZsNoc8v","cellView":"form","executionInfo":{"status":"ok","timestamp":1735868239825,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# @title Create a bucket.\n","BUCKET_URI = f\"gs://mlops-{PROJECT_ID}-0103\"\n","! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htaYispjQ88d","executionInfo":{"status":"ok","timestamp":1735868246286,"user_tz":-540,"elapsed":3532,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"3106b21c-0938-4af7-d57f-e550a408f1a2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating gs://mlops-ai-hangsik-0103/...\n","ServiceException: 409 A Cloud Storage bucket named 'mlops-ai-hangsik-0103' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"]}]},{"cell_type":"code","source":["# @title Service account\n","shell_output = ! gcloud projects describe  $PROJECT_ID\n","project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n","SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n","print(f\"SERVICE_ACCOUNT: {SERVICE_ACCOUNT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BDfphYcQ_yV","executionInfo":{"status":"ok","timestamp":1735868248816,"user_tz":-540,"elapsed":1428,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"8650be62-138a-4db5-eac6-d8952403729a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["SERVICE_ACCOUNT: 721521243942-compute@developer.gserviceaccount.com\n"]}]},{"cell_type":"code","source":["! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n","! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-oHKkkpRBFp","executionInfo":{"status":"ok","timestamp":1735868254162,"user_tz":-540,"elapsed":4137,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"395bb750-3c39-458e-84c1-ef786d0deffe"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["No changes made to gs://mlops-ai-hangsik-0103/\n","No changes made to gs://mlops-ai-hangsik-0103/\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"import_aip:mbsdk","executionInfo":{"status":"ok","timestamp":1735868260177,"user_tz":-540,"elapsed":3756,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["# @title Import libraries\n","import os\n","import uuid\n","\n","import google.cloud.aiplatform as aiplatform"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Pg2yfCvuQZl6","executionInfo":{"status":"ok","timestamp":1735868260180,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["# @title Initialize Vertex AI SDK for Python\n","aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"]},{"cell_type":"markdown","metadata":{"id":"3cd64a48e0f4"},"source":["## Cloud development in Vertex AI Training"]},{"cell_type":"markdown","metadata":{"id":"examine_training_package"},"source":["#### Package layout\n","\n","Before you start the training, you'll look at how a Python package is assembled for a custom training job. When unarchived, the package contains the following directory/file layout.\n","\n","- PKG-INFO\n","- README.md\n","- setup.cfg\n","- setup.py\n","- trainer\n","  - \\_\\_init\\_\\_.py\n","  - task.py\n","\n","The files `setup.cfg` and `setup.py` are the instructions for installing the package into the operating environment of the Docker image.\n","\n","The file `trainer/task.py` is the Python script for executing the custom training job. *Note*, when we referred to it in the worker pool specification, we replace the directory slash with a dot (`trainer.task`) and dropped the file suffix (`.py`).\n","\n","#### Package Assembly\n","\n","In the following cells, assemble the training package."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"pW08bB6oQZmB","executionInfo":{"status":"ok","timestamp":1735868283830,"user_tz":-540,"elapsed":850,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["# Make folder for Python training script\n","! rm -rf custom\n","! mkdir custom\n","\n","# Add package information\n","! touch custom/README.md\n","\n","# setup.cfg and setup.py are the instructions for installing the package into the operating environment of the Docker image.\n","\n","setup_cfg = \"[egg_info]\\n\\ntag_build =\\n\\ntag_date = 0\"\n","! echo \"$setup_cfg\" > custom/setup.cfg\n","\n","setup_py = \"import setuptools\\n\\nsetuptools.setup(\\n\\n    install_requires=[\\n\\n        'google-cloud-aiplatform',\\n\\n  ],\\n\\n    packages=setuptools.find_packages())\"\n","! echo \"$setup_py\" > custom/setup.py\n","\n","pkg_info = \"Metadata-Version: 1.0\\n\\nName: Synethic Training Script for Experiments\\n\\nVersion: 0.0.0\\n\\nSummary: Demostration training script\\n\\nHome-page: www.google.com\\n\\nAuthor: Google\\n\\nAuthor-email: aferlitsch@google.com\\n\\nLicense: Public\\n\\nDescription: Demo\\n\\nPlatform: Vertex\"\n","! echo \"$pkg_info\" > custom/PKG-INFO\n","\n","# Make the training subfolder\n","! mkdir custom/trainer\n","! touch custom/trainer/__init__.py"]},{"cell_type":"markdown","metadata":{"id":"50c0e24489df"},"source":["#### Create synthetic training script\n","\n","First, write a synthetic training script. It won't actually train a model, but instead mimics the training of the model:\n","\n","- Argument parsing\n","  - `experiment`: The name of the experiment.\n","  - `run`: The name of the run within the experiment.\n","  - `epochs`: The number of epochs.\n","  - `dataset-uri`: The Cloud Storage location of the training data.\n","  - `model-dir`: The Cloud Storage location to save the trained model artifacts.\n","- Training functions\n","  - `get_data()`:\n","      - Get the training data.\n","      - Create the input dataset artifact.\n","      - Attach dataset artifact as input to execution context.\n","  - `get_model()`:\n","      - Get the model architecture.\n","  - `train_model()`:\n","      - Train the model.\n","  - `save_model()`:\n","      - Save the model.\n","      - Create the output model artifact.\n","      - Attach model artifact as output to execution context.\n","- Initialize the experiment (`init()`) and start a run (`start_run()`) within the experiment.\n","- Wrap the training with a `start_execution()`.\n","- Log the lineage to the experiment parameters (`log_metrics({\"lineage\"...)`).\n","- End the experiment run (`end_run()`)."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"aed1431dccaf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735868294888,"user_tz":-540,"elapsed":31,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"bd1003c2-f040-4fd6-9a1c-326f76d1e021"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing custom/trainer/task.py\n"]}],"source":["%%writefile custom/trainer/task.py\n","\n","import argparse\n","import os\n","\n","import google.cloud.aiplatform as aiplatform\n","\n","parser = argparse.ArgumentParser()\n","# Args for experiment\n","parser.add_argument('--experiment', dest='experiment',\n","                    required=True, type=str,\n","                    help='Name of experiment')\n","parser.add_argument('--run', dest='run',\n","                    required=True, type=str,\n","                    help='Name of run within the experiment')\n","\n","# Hyperparameters for experiment\n","parser.add_argument('--epochs', dest='epochs',\n","                    default=10, type=int,\n","                    help='Number of epochs.')\n","\n","parser.add_argument('--dataset-uri', dest='dataset_uri',\n","                    required=True, type=str,\n","                    help='Location of the dataset')\n","\n","parser.add_argument('--model-dir', dest='model_dir',\n","                    default=os.getenv(\"AIP_MODEL_DIR\"), type=str,\n","                    help='Storage location for the model')\n","args = parser.parse_args()\n","\n","def get_data(dataset_uri, execution):\n","    # get the training data\n","\n","    dataset_artifact = aiplatform.Artifact.create(\n","        schema_title=\"system.Dataset\", display_name=\"example_dataset\", uri=dataset_uri\n","    )\n","\n","    execution.assign_input_artifacts([dataset_artifact])\n","\n","    return None\n","\n","def get_model():\n","    # get or create the model architecture\n","    return None\n","\n","def train_model(dataset, model, epochs):\n","    aiplatform.log_params({\"epochs\": epochs})\n","    # train the model\n","    return model\n","\n","def save_model(model, model_dir, execution):\n","    # save the model\n","\n","    model_artifact = aiplatform.Artifact.create(\n","        schema_title=\"system.Model\", display_name=\"example_model\", uri=model_dir\n","    )\n","    execution.assign_output_artifacts([model_artifact])\n","\n","# Create a run within the experiment\n","aiplatform.init(experiment=args.experiment)\n","aiplatform.start_run(args.run)\n","\n","with aiplatform.start_execution(\n","    schema_title=\"system.ContainerExecution\", display_name=\"example_training\"\n",") as execution:\n","    dataset = get_data(args.dataset_uri, execution)\n","    model = get_model()\n","    model = train_model(dataset, model, args.epochs)\n","    save_model(model, args.model_dir, execution)\n","\n","    # Store the lineage link in the experiment\n","    aiplatform.log_metrics({\"lineage\": execution.get_output_artifacts()[0].lineage_console_uri})\n","\n","aiplatform.end_run()"]},{"cell_type":"markdown","metadata":{"id":"tarball_training_script"},"source":["#### Store training script on your Cloud Storage bucket\n","\n","Next, package the training folder into a compressed tar ball, and then store it in your Cloud Storage bucket."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"AAW9EL78QZmB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735868301057,"user_tz":-540,"elapsed":2631,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"7a994651-5031-4488-e70d-231185bb8f71"},"outputs":[{"output_type":"stream","name":"stdout","text":["custom/\n","custom/README.md\n","custom/setup.cfg\n","custom/setup.py\n","custom/trainer/\n","custom/trainer/__init__.py\n","custom/trainer/task.py\n","custom/PKG-INFO\n","Copying file://custom.tar.gz [Content-Type=application/x-tar]...\n","/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n","Operation completed over 1 objects/1.3 KiB.                                      \n"]}],"source":["! rm -f custom.tar custom.tar.gz\n","! tar cvf custom.tar custom\n","! gzip custom.tar\n","! gsutil cp custom.tar.gz $BUCKET_URI/trainer.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"create_custom_pp_training_job:mbsdk,no_model"},"source":["#### Create custom training job\n","\n","A custom training job is created with the `CustomTrainingJob` class, with the following parameters:\n","\n","- `display_name`: The human readable name for the custom training job.\n","- `container_uri`: The training container image.\n","\n","- `python_package_gcs_uri`: The location of the Python training package as a tarball.\n","- `python_module_name`: The relative path to the training script in the Python package.\n","\n","*Note:* There is no requirements parameter. You specify any requirements in the `setup.py` script in your Python package."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"05_12BLVQZmB","executionInfo":{"status":"ok","timestamp":1735868305609,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["DISPLAY_NAME = \"example\"\n","TRAIN_IMAGE = \"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-12.py310:latest\"\n","\n","job = aiplatform.CustomPythonPackageTrainingJob(\n","    display_name=DISPLAY_NAME,\n","    python_package_gcs_uri=f\"{BUCKET_URI}/trainer.tar.gz\",\n","    python_module_name=\"trainer.task\",\n","    container_uri=TRAIN_IMAGE,\n",")"]},{"cell_type":"markdown","metadata":{"id":"run_custom_container_training_job:no_model"},"source":["#### Run the custom training job\n","\n","Next, run the custom training job to start the training job by invoking the method `run()`, with the following parameters:\n","\n","- `args`: The arguments to pass to the training script\n","    - `model_dir`: The Cloud Storage location to store the model.\n","    - `dataset_uri`: The Cloud Storage location of the dataset.\n","    - `epochs`: The number of epochs (hyperparameter).\n","    - `experiment`: The name of the experiment.\n","    - `run`: The name of the run within the experiment.\n","- `replica_count`: The number of VM instances.\n","- `machine_type`: The machine type for each VM instance."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"260f972398e5","colab":{"base_uri":"https://localhost:8080/","height":667},"executionInfo":{"status":"ok","timestamp":1735870844607,"user_tz":-540,"elapsed":2535864,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"95e4bf1d-6bcc-4c6c-cb92-3b01351a00df"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","        \n","    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n","    <style>\n","      .view-vertex-resource,\n","      .view-vertex-resource:hover,\n","      .view-vertex-resource:visited {\n","        position: relative;\n","        display: inline-flex;\n","        flex-direction: row;\n","        height: 32px;\n","        padding: 0 12px;\n","          margin: 4px 18px;\n","        gap: 4px;\n","        border-radius: 4px;\n","\n","        align-items: center;\n","        justify-content: center;\n","        background-color: rgb(255, 255, 255);\n","        color: rgb(51, 103, 214);\n","\n","        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n","        font-size: 13px;\n","        font-weight: 500;\n","        text-transform: uppercase;\n","        text-decoration: none !important;\n","\n","        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n","        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n","      }\n","      .view-vertex-resource:active {\n","        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n","      }\n","      .view-vertex-resource:active .view-vertex-ripple::before {\n","        position: absolute;\n","        top: 0;\n","        bottom: 0;\n","        left: 0;\n","        right: 0;\n","        border-radius: 4px;\n","        pointer-events: none;\n","\n","        content: '';\n","        background-color: rgb(51, 103, 214);\n","        opacity: 0.12;\n","      }\n","      .view-vertex-icon {\n","        font-size: 18px;\n","      }\n","    </style>\n","  \n","        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-a2de2723-2b33-47c9-8b42-aa9b172364fb\" href=\"#view-view-vertex-resource-a2de2723-2b33-47c9-8b42-aa9b172364fb\">\n","          <span class=\"material-icons view-vertex-icon\">science</span>\n","          <span>View Experiment</span>\n","        </a>\n","        \n","        <script>\n","          (function () {\n","            const link = document.getElementById('view-vertex-resource-a2de2723-2b33-47c9-8b42-aa9b172364fb');\n","            link.addEventListener('click', (e) => {\n","              if (window.google?.colab?.openUrl) {\n","                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/example-6eb0888e-c973-11ef-a7ad-0242ac1c000c/runs?project=ai-hangsik');\n","              } else {\n","                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/example-6eb0888e-c973-11ef-a7ad-0242ac1c000c/runs?project=ai-hangsik', '_blank');\n","              }\n","              e.stopPropagation();\n","              e.preventDefault();\n","            });\n","          })();\n","        </script>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.training_jobs:Training Output directory:\n","gs://mlops-ai-hangsik-0103/aiplatform-custom-training-2025-01-03-01:38:31.113 \n","INFO:google.cloud.aiplatform.training_jobs:View Training:\n","https://console.cloud.google.com/ai/platform/locations/us-central1/training/3609361013704491008?project=721521243942\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:View backing custom job:\n","https://console.cloud.google.com/ai/platform/locations/us-central1/training/1769618575691087872?project=721521243942\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.training_jobs:CustomPythonPackageTrainingJob run completed. Resource name: projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008\n","WARNING:google.cloud.aiplatform.training_jobs:Training did not produce a Managed Model returning None. Training Pipeline projects/721521243942/locations/us-central1/trainingPipelines/3609361013704491008 is not configured to upload a Model. Create the Training Pipeline with model_serving_container_image_uri and model_display_name passed in. Ensure that your training script saves to model to os.environ['AIP_MODEL_DIR'].\n"]}],"source":["TRAIN_COMPUTE = \"n1-standard-4\"\n","EXPERIMENT_NAME = f\"example-{uuid.uuid1()}\"\n","aiplatform.init(experiment=EXPERIMENT_NAME)\n","\n","CMDARGS = [\n","    \"--model-dir=\" + BUCKET_URI,\n","    \"--dataset-uri=gs://example/foo.csv\",\n","    \"--epochs=5\",\n","    f\"--experiment={EXPERIMENT_NAME}\",\n","    \"--run=run-1\",\n","]\n","\n","job.run(\n","    args=CMDARGS,\n","    replica_count=1,\n","    machine_type=TRAIN_COMPUTE,\n","    service_account=SERVICE_ACCOUNT,\n","    sync=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"5f40912e6500"},"source":["#### Get the experiment results\n","\n","Next, use the experiment name as a parameter to the method `get_experiment_df()` to get the results of the experiment as a pandas dataframe.\n","\n","In this example, you stored the resource URI to the lineage as a metric value `lineage` in the execution run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7e9671712230"},"outputs":[],"source":["experiment_df = aiplatform.get_experiment_df()\n","experiment_df = experiment_df[experiment_df.experiment_name == EXPERIMENT_NAME]\n","print(experiment_df.T)\n"]},{"cell_type":"markdown","metadata":{"id":"65a65f847332"},"source":["#### Visualize the artifact lineage\n","\n","Next, open the link below to visualize the artifact lineage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5a02e7d92c7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733698156784,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"5cda895b-8f14-40a2-989f-188633c45732"},"outputs":[{"output_type":"stream","name":"stdout","text":["Open the following link https://console.cloud.google.com/vertex-ai/locations/us-central1/metadata-stores/default/artifacts/d3229864-4544-4b60-ad21-6b146196fff7?project=ai-hangsik\n"]}],"source":["try:\n","    print(\"Open the following link\", experiment_df[\"metric.lineage\"][0])\n","except Exception as e:\n","    print(e)"]},{"cell_type":"markdown","metadata":{"id":"d4ba591be8ec"},"source":["#### Delete the custom training job\n","\n","You can delete your custom training job using the `delete()` method."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5436ab06482a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733698156784,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"080bf853-b6e8-4f41-9e3f-18d97ef9c865"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.base:Deleting CustomPythonPackageTrainingJob : projects/721521243942/locations/us-central1/trainingPipelines/8801799728074326016\n","INFO:google.cloud.aiplatform.base:CustomPythonPackageTrainingJob deleted. . Resource name: projects/721521243942/locations/us-central1/trainingPipelines/8801799728074326016\n","INFO:google.cloud.aiplatform.base:Deleting CustomPythonPackageTrainingJob resource: projects/721521243942/locations/us-central1/trainingPipelines/8801799728074326016\n","INFO:google.cloud.aiplatform.base:Delete CustomPythonPackageTrainingJob backing LRO: projects/721521243942/locations/us-central1/operations/7826804699767504896\n","INFO:google.cloud.aiplatform.base:CustomPythonPackageTrainingJob resource projects/721521243942/locations/us-central1/trainingPipelines/8801799728074326016 deleted.\n"]}],"source":["job.delete()"]},{"cell_type":"markdown","metadata":{"id":"e508c159d712"},"source":["#### Delete the experiment\n","\n","Since the experiment was created within Vertex AI Training, to delete the experiment you use the `list()` method to obtain all the experiments for the project, and then filter on the experiment name."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1a1b5fcbfde0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733698159300,"user_tz":-540,"elapsed":2518,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"94d528b0-00e7-45b8-82eb-66873988908d"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:google.cloud.aiplatform.metadata.experiment_run_resource:Experiment run run-1 skipped backing tensorboard run deletion.\n","To delete backing tensorboard run, execute the following:\n","tensorboard_run_artifact = aiplatform.metadata.artifact.Artifact(artifact_name=f\"example-cb076ade-b5b5-11ef-8a30-0242ac1c000c-run-1-tb-run\")\n","tensorboard_run_resource = aiplatform.TensorboardRun(tensorboard_run_artifact.metadata[\"resourceName\"])\n","tensorboard_run_resource.delete()\n","tensorboard_run_artifact.delete()\n","INFO:google.cloud.aiplatform.base:Deleting Context : projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c-run-1\n","INFO:google.cloud.aiplatform.base:Context deleted. . Resource name: projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c-run-1\n","INFO:google.cloud.aiplatform.base:Deleting Context resource: projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c-run-1\n","INFO:google.cloud.aiplatform.base:Delete Context backing LRO: projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c-run-1/operations/3630294271988334592\n","INFO:google.cloud.aiplatform.base:Context resource projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c-run-1 deleted.\n","INFO:google.cloud.aiplatform.base:Deleting Context : projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c\n","INFO:google.cloud.aiplatform.base:Context deleted. . Resource name: projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c\n","INFO:google.cloud.aiplatform.base:Deleting Context resource: projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c\n","INFO:google.cloud.aiplatform.base:Delete Context backing LRO: projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c/operations/296786122804035584\n","INFO:google.cloud.aiplatform.base:Context resource projects/721521243942/locations/us-central1/metadataStores/default/contexts/example-cb076ade-b5b5-11ef-8a30-0242ac1c000c deleted.\n"]}],"source":["experiments = aiplatform.Experiment.list()\n","for experiment in experiments:\n","    if experiment.name == EXPERIMENT_NAME:\n","        experiment.delete()"]},{"cell_type":"markdown","metadata":{"id":"nHMIv5nJQZmC"},"source":["# Cleaning up\n","\n","To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n","project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n","\n","Otherwise, you can delete the individual resources you created in this tutorial."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e89f43b3df49"},"outputs":[],"source":["! rm -rf custom\n","\n","delete_bucket = False\n","\n","if delete_bucket:\n","    ! gsutil rm -rf {BUCKET_URI}"]}],"metadata":{"colab":{"toc_visible":true,"provenance":[{"file_id":"16oQMvG2eI2z3lNM7BYOH3lRrBlyXHRFw","timestamp":1735866347910},{"file_id":"1kM_88jm184hOyBZBZRkrf5d9qmXlXLtt","timestamp":1735866211656},{"file_id":"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/experiments/get_started_with_vertex_experiments.ipynb","timestamp":1733694695118}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ur8xi4C7S06n"},"outputs":[],"source":["# Copyright 2021 Google LLC\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"JAPoU8Sm5E6e"},"source":["# Track artifacts and metrics across Vertex AI Pipelines runs\n","\n","Learn more about [Vertex ML Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata) and [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction).\n","\n","*   https://colab.sandbox.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ml_metadata/vertex-pipelines-ml-metadata.ipynb\n","\n","\n","### Dataset\n","\n","This notebook uses scikit-learn to train a model and classify bean types using the [Dry Beans Dataset](https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset) from UCI Machine Learning. This is a tabular dataset that includes measurements and characteristics of seven different types of beans taken from images.\n"]},{"cell_type":"markdown","metadata":{"id":"No17Cw5hgx12"},"source":["## Install Vertex AI SDK"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"wyy5Lbnzg5fi","executionInfo":{"status":"ok","timestamp":1733693549232,"user_tz":-540,"elapsed":43768,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c7c678ec-6450-4fba-efbb-a0f0c6c00b26"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/343.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m337.9/343.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.6/343.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for kfp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for kfp-server-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","langsmith 0.1.147 requires requests-toolbelt<2.0.0,>=1.0.0, but you have requests-toolbelt 0.10.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n","                                 kfp"]},{"cell_type":"code","source":["! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5BD_7PvQDzv","executionInfo":{"status":"ok","timestamp":1733693594138,"user_tz":-540,"elapsed":1461,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"3775a540-ba1a-4af0-f45a-af14792c60a9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["KFP SDK version: 2.10.1\n"]}]},{"cell_type":"markdown","source":["## Configuration"],"metadata":{"id":"Uz8cDnFWQHNM"}},{"cell_type":"markdown","metadata":{"id":"dmWOrTJ3gx13"},"source":["### Authenticate your notebook environment"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NyKGtVQjgx13","executionInfo":{"status":"ok","timestamp":1733693609253,"user_tz":-540,"elapsed":14510,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"08830546-21ec-4352-9f5d-1783fc3d0f50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated property [core/project].\n"]}],"source":["import sys\n","from IPython.display import Markdown, display\n","\n","PROJECT_ID=\"ai-hangsik\"\n","LOCATION=\"us-central1\"\n","\n","# For only colab user, no need this process for Colab Enterprise in Vertex AI.\n","if \"google.colab\" in sys.modules:\n","    from google.colab import auth\n","    auth.authenticate_user(project_id=PROJECT_ID)\n","\n","# set project.\n","!gcloud config set project {PROJECT_ID}"]},{"cell_type":"markdown","source":["### Initialize Vertex AI SDK"],"metadata":{"id":"4dvc1w7cQeEk"}},{"cell_type":"code","source":["\n","from google.cloud import aiplatform\n","\n","aiplatform.init(project=PROJECT_ID, location=LOCATION)"],"metadata":{"id":"J-kjglrqQcH1","executionInfo":{"status":"ok","timestamp":1733693612522,"user_tz":-540,"elapsed":3271,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"qD8HnRpFM_1Y"}},{"cell_type":"markdown","source":["### Create a bucket"],"metadata":{"id":"xXcmhnHsQlTr"}},{"cell_type":"code","source":["# Create a bucket.\n","BUCKET_URI = f\"gs://mlops-{PROJECT_ID}-1209\"\n","! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVXmwapOQk0V","executionInfo":{"status":"ok","timestamp":1733693616270,"user_tz":-540,"elapsed":3751,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"8e407b90-390e-420f-82e7-f01893a52ff7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating gs://mlops-ai-hangsik-1209/...\n","ServiceException: 409 A Cloud Storage bucket named 'mlops-ai-hangsik-1209' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"]}]},{"cell_type":"code","source":["shell_output = ! gcloud projects describe  $PROJECT_ID\n","project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n","\n","SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n","\n","print(f\"SERVICE_ACCOUNT: {SERVICE_ACCOUNT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eC9F9UbuQofT","executionInfo":{"status":"ok","timestamp":1733693618167,"user_tz":-540,"elapsed":1899,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"12a323a2-2d1b-4018-bcf7-976f7d3a13aa"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["SERVICE_ACCOUNT: 721521243942-compute@developer.gserviceaccount.com\n"]}]},{"cell_type":"markdown","source":["### Set access for Service account"],"metadata":{"id":"1OrvDpzjQwEr"}},{"cell_type":"code","source":["! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_URI\n","! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_URI"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw3dq3ibQxWK","executionInfo":{"status":"ok","timestamp":1733693623460,"user_tz":-540,"elapsed":5295,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"8b085cda-4154-48b5-b1ad-830285c9eaba"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["No changes made to gs://mlops-ai-hangsik-1209/\n","No changes made to gs://mlops-ai-hangsik-1209/\n"]}]},{"cell_type":"markdown","metadata":{"id":"XoEqT2Y4DJmf"},"source":["### Import libraries and define constants"]},{"cell_type":"markdown","metadata":{"id":"Y9Uo3tifg1kx"},"source":["Import required libraries."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"pRUOFELefqf1","executionInfo":{"status":"ok","timestamp":1733693624476,"user_tz":-540,"elapsed":1017,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","from google.cloud import aiplatform, aiplatform_v1beta1\n","from google.cloud.aiplatform import pipeline_jobs\n","from kfp import compiler, dsl\n","from kfp.dsl import (Artifact, Dataset, Input, Metrics, Model, Output,\n","                     OutputPath, component)"]},{"cell_type":"markdown","metadata":{"id":"xtXZWmYqJ1bh"},"source":["Define some constants"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"JIOrI-hoJ46P","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1733693626118,"user_tz":-540,"elapsed":347,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"ba165282-701b-4fef-c03d-fa5a97aed2a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'gs://mlops-ai-hangsik-1209/pipeline/custom/metadata'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}],"source":["# PATH = get_ipython().run_line_magic(\"env\", \"PATH\")\n","# %env PATH={PATH}:/home/jupyter/.local/bin\n","# REGION = \"asia-northeast3\"\n","\n","PIPELINE_ROOT = f\"{BUCKET_URI}/pipeline/custom/metadata\"\n","PIPELINE_ROOT"]},{"cell_type":"markdown","metadata":{"id":"l1YW2pgyegFP"},"source":["## Create a pipeline\n"]},{"cell_type":"markdown","metadata":{"id":"KPY41M9_AhZU"},"source":["### Create and define Python function based components"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"RiQuMv4bmpuV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733693628755,"user_tz":-540,"elapsed":296,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"88af43c9-fbed-410b-a9e4-b252fb8e12c4"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-459c753a459f>:1: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n","  @component(\n","<ipython-input-10-459c753a459f>:7: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n","  def get_dataframe(\n"]}],"source":["@component(\n","    packages_to_install=[\"google-cloud-bigquery[pandas]\", \"pyarrow\"],\n","    base_image=\"python:3.10\",\n","    output_component_file=\"get_dataframe.yaml\",\n",")\n","\n","def get_dataframe(\n","    project_id: str, bq_table: str, output_data_path: OutputPath(\"Dataset\")\n","):\n","    from google.cloud import bigquery\n","\n","    bqclient = bigquery.Client(project=project_id)\n","    table = bigquery.TableReference.from_string(bq_table)\n","    rows = bqclient.list_rows(table)\n","    dataframe = rows.to_dataframe(\n","        create_bqstorage_client=True,\n","    )\n","    dataframe = dataframe.sample(frac=1, random_state=2)\n","    dataframe.to_csv(output_data_path)"]},{"cell_type":"markdown","metadata":{"id":"Y06J7A7yU21t"},"source":["Next, create a component to train a scikit-learn model. This component does the following:\n","* Imports a CSV as a pandas DataFrame.\n","* Splits the DataFrame into train and test sets.\n","* Trains a scikit-learn model.\n","* Logs metrics from the model.\n","* Saves the model artifacts as a local `model.joblib` file."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"p5JBCBKyH-NC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733693633947,"user_tz":-540,"elapsed":296,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"9533400c-aa98-4075-f4a4-a46891729e75"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-5a4ca1828538>:1: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n","  @component(\n","<ipython-input-11-5a4ca1828538>:6: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n","  def sklearn_train(\n"]}],"source":["@component(\n","    packages_to_install=[\"scikit-learn==1.2\", \"pandas\", \"joblib\", \"numpy==1.26.4\"],\n","    base_image=\"python:3.10\",\n","    output_component_file=\"sklearn_train.yaml\",\n",")\n","def sklearn_train(\n","    dataset: Input[Dataset], metrics: Output[Metrics], model: Output[Model]\n","):\n","    import pandas as pd\n","    from joblib import dump\n","    from sklearn.model_selection import train_test_split\n","    from sklearn.tree import DecisionTreeClassifier\n","\n","    df = pd.read_csv(dataset.path)\n","    labels = df.pop(\"Class\").tolist()\n","    data = df.values.tolist()\n","    x_train, x_test, y_train, y_test = train_test_split(data, labels)\n","\n","    skmodel = DecisionTreeClassifier()\n","    skmodel.fit(x_train, y_train)\n","    score = skmodel.score(x_test, y_test)\n","    print(\"accuracy is:\", score)\n","\n","    metrics.log_params[\"units\"] = (score * 30.0)\n","    metrics.log_params[\"batch_size\"] = 120\n","    metrics.log_params[\"note\"] = \"hyperparameter\"\n","\n","    metrics.log_metric(\"accuracy\", (score * 100.0))\n","    metrics.log_metric(\"framework\", \"Scikit Learn\")\n","    metrics.log_metric(\"dataset_size\", len(df))\n","\n","    dump(skmodel, model.path + \".joblib\")\n"]},{"cell_type":"markdown","metadata":{"id":"gaNNTFPaU7KT"},"source":["Finally, the last component  takes the trained model from the previous step, uploads the model to Vertex AI, and deploys it to an endpoint:"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"VGq5QCoyIEWJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733693638442,"user_tz":-540,"elapsed":299,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"e8dcc5bf-f5d0-41a4-c47e-1fb23301b0fe"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-57c1c2d4c506>:1: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n","  @component(\n","<ipython-input-12-57c1c2d4c506>:6: DeprecationWarning: output_component_file parameter is deprecated and will eventually be removed. Please use `Compiler().compile()` to compile a component instead.\n","  def deploy_model(\n"]}],"source":["@component(\n","    packages_to_install=[\"google-cloud-aiplatform\"],\n","    base_image=\"python:3.10\",\n","    output_component_file=\"deploy_model.yaml\",\n",")\n","def deploy_model(\n","    model: Input[Model],\n","    project: str,\n","    region: str,\n","    vertex_endpoint: Output[Artifact],\n","    vertex_model: Output[Model],\n","):\n","    from google.cloud import aiplatform\n","\n","    aiplatform.init(project=project, location=region)\n","\n","    deployed_model = aiplatform.Model.upload(\n","        display_name=\"tracking_metadata_pipeline\",\n","        artifact_uri=model.uri.replace(\"model\", \"\"),\n","        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest\",\n","    )\n","    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n","\n","    # Save data to the output params\n","    vertex_endpoint.uri = endpoint.resource_name\n","    vertex_model.uri = deployed_model.resource_name"]},{"cell_type":"markdown","metadata":{"id":"UBXUgxgqA_GB"},"source":["### Define and compile the pipeline"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"66odBYKrIN4q","executionInfo":{"status":"ok","timestamp":1733693641193,"user_tz":-540,"elapsed":298,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["@dsl.pipeline(\n","    # Default pipeline root. You can override it when submitting the pipeline.\n","    pipeline_root=PIPELINE_ROOT,\n","    # A name for the pipeline.\n","    name=\"tracking_metadata_pipeline\",\n",")\n","def pipeline(\n","    bq_table: str,\n","    output_data_path: str,\n","    project: str,\n","    region: str,\n","):\n","    dataset_task = get_dataframe(project_id=project, bq_table=bq_table)\n","\n","    model_task = sklearn_train(dataset=dataset_task.output)\n","\n","    deploy_model(model=model_task.outputs[\"model\"], project=project, region=region)"]},{"cell_type":"markdown","metadata":{"id":"910541af051c"},"source":["The following generates a JSON file that is then used to run the pipeline:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"o_wnT10RJ7-W","executionInfo":{"status":"ok","timestamp":1733693643530,"user_tz":-540,"elapsed":301,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"tracking_metadata_pipeline.json\")"]},{"cell_type":"markdown","metadata":{"id":"u-iTnzt3B6Z_"},"source":["### Initiate pipeline runs"]},{"cell_type":"markdown","source":["Create a pipeline run using a small version of the same dataset."],"metadata":{"id":"OpCeifpfXFfS"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"ff4aee966c5f","executionInfo":{"status":"ok","timestamp":1733693645761,"user_tz":-540,"elapsed":301,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["from datetime import datetime\n","TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n","\n","run1 = pipeline_jobs.PipelineJob(\n","    display_name=\"tracking_metadata_pipeline\",\n","    template_path=\"tracking_metadata_pipeline.json\",\n","    job_id=\"tracking-metadata-pipeline-small-{}\".format(TIMESTAMP),\n","    parameter_values={\n","        \"bq_table\": \"sara-vertex-demos.beans_demo.small_dataset\",\n","        \"output_data_path\": \"data.csv\",\n","        \"project\": PROJECT_ID,\n","        \"region\": LOCATION,\n","    },\n","    enable_caching=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"555ac88a22cf"},"source":["Next, create another pipeline run using a larger version of the same dataset."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"3d9fcb6a4a9e","executionInfo":{"status":"ok","timestamp":1733693649050,"user_tz":-540,"elapsed":306,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}}},"outputs":[],"source":["run2 = pipeline_jobs.PipelineJob(\n","    display_name=\"tracking_metadata_pipeline\",\n","    template_path=\"tracking_metadata_pipeline.json\",\n","    job_id=\"tracking-metadata-pipeline-large-{}\".format(TIMESTAMP),\n","    parameter_values={\n","        \"bq_table\": \"sara-vertex-demos.beans_demo.large_dataset\",\n","        \"output_data_path\": \"data.csv\",\n","        \"project\": PROJECT_ID,\n","        \"region\": LOCATION,\n","    },\n","    enable_caching=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"5670722f7668"},"source":["Finally, kick off pipeline executions for both runs. It's best to do this in two separate notebook cells so you can see the output for each run."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"1f477f5565c6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733693652576,"user_tz":-540,"elapsed":1512,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"de916ae3-8c6f-4fdc-eefb-24bcd2990ce8"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/721521243942/locations/us-central1/pipelineJobs/tracking-metadata-pipeline-small-20241208213405\n","INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n","INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/721521243942/locations/us-central1/pipelineJobs/tracking-metadata-pipeline-small-20241208213405')\n","INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n","https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tracking-metadata-pipeline-small-20241208213405?project=721521243942\n"]}],"source":["run1.submit()"]},{"cell_type":"markdown","metadata":{"id":"6e682e41af78"},"source":["Then, kick off the second run:"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"cb263e503ced","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733693654136,"user_tz":-540,"elapsed":1127,"user":{"displayName":"Hangsik Shin","userId":"04632555686962088332"}},"outputId":"5a71dd5a-2332-48c8-986c-dda8f95d6502"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/721521243942/locations/us-central1/pipelineJobs/tracking-metadata-pipeline-large-20241208213405\n","INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n","INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/721521243942/locations/us-central1/pipelineJobs/tracking-metadata-pipeline-large-20241208213405')\n","INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n","https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/tracking-metadata-pipeline-large-20241208213405?project=721521243942\n"]}],"source":["run2.submit()"]},{"cell_type":"markdown","metadata":{"id":"TpV-iwP9qw9c"},"source":["## Cleaning up\n","\n","To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n","project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n","\n","If you don't want to delete the project, do the following to clean up the resources you used:\n","\n","* If you used Vertex AI Workbench notebooks to run this, stop or delete the notebook instance.\n","\n","* The pipeline runs you executed deployed endpoints in Vertex AI. Navigate to the [Google Cloud console](https://console.cloud.google.com/vertex-ai/endpoints) to delete those endpoints.\n","\n","* Delete the [Cloud Storage bucket](https://console.cloud.google.com/storage/browser/) you created.\n","\n","Alternatively, you can execute the below cell to clean up the resources used in this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f2c21373a498"},"outputs":[],"source":["# delete pipelines\n","try:\n","    run1.delete()\n","    run2.delete()\n","except Exception as e:\n","    print(e)\n","\n","# undeploy model from endpoints\n","endpoints = aiplatform.Endpoint.list(\n","    filter='display_name=\"beans-model-pipeline_endpoint\"'\n",")\n","for endpoint in endpoints:\n","    deployed_models = endpoint.list_models()\n","    for deployed_model in deployed_models:\n","        endpoint.undeploy(deployed_model_id=deployed_model.id)\n","    # delete endpoint\n","    endpoint.delete()\n","\n","# delete model\n","model_ids = aiplatform.Model.list(filter='display_name=\"beans-model-pipeline\"')\n","for model_id in model_ids:\n","    model = aiplatform.Model(model_name=model_id.resource_name)\n","    model.delete()\n","\n","# delete locally generated files\n","! rm -rf beans_deploy_component.yaml beans_model_component.yaml create_dataset.yaml mlmd_pipeline.json\n","\n","# delete cloud storage bucket\n","delete_bucket = False  # set True for deletion\n","if delete_bucket:\n","    ! gsutil rm -rf {BUCKET_URI}"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}